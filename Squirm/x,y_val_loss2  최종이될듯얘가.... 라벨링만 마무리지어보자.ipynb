{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab15828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretreatment(wav):  \n",
    "    # 전처리 소수점 0.3 이하까지만\n",
    "    y=[]\n",
    "    for i in range(len(wav)):\n",
    "        y.append(round(wav[i],3))\n",
    "        \n",
    "    # 0.02 이하는 0으로    \n",
    "    t=[]\n",
    "    for i in range(len(y)):\n",
    "        if y[i]>=0.02 or  y[i]<=-0.02:\n",
    "            t.append(y[i])\n",
    "        else:\n",
    "            y[i]=0\n",
    "            t.append(y[i])\n",
    "    \n",
    "    # 파장 나누기\n",
    "    re_time =[] # 파장 나눈 위치 저장 리스트\n",
    "    count = 0 # 0의 개수 세기\n",
    "    # and len(re_time)%2==0\n",
    "    for i in range(len(t)):\n",
    "        if t[i]==0:\n",
    "            count+=1\n",
    "        elif t[i]!=0 and count>=500:\n",
    "            re_time.append(i)\n",
    "            count=0\n",
    "        else:\n",
    "            count=0\n",
    "    \n",
    "    # 파장 길이 구하기\n",
    "    l_list=[] # 파장 길이 저장 리스트 (x)\n",
    "    l_count=0 # 0의 개수 카운트\n",
    "    for i in range(len(re_time)):\n",
    "        if i == len(re_time)-1:\n",
    "            for j in range(len(t[re_time[i]:])):\n",
    "                a = re_time[i]\n",
    "                if t[a+j]!=0:\n",
    "                    l_count+=1\n",
    "            l_list.append(l_count)\n",
    "            l_count=0\n",
    "        else:\n",
    "            for j in range(len(t[re_time[i]:re_time[i+1]])):\n",
    "                a = re_time[i]\n",
    "                if t[a+j]!=0:\n",
    "                    l_count+=1\n",
    "            l_list.append(l_count)\n",
    "            l_count=0\n",
    "            l_list.append\n",
    "\n",
    "    # 두개로 나누기\n",
    "    s_all=sum(l_list)/2\n",
    "    b=0 # 각 파장 길이 중첩 변수\n",
    "    c=0 # 몇번째 파장까지 나누는지 결정 변수\n",
    "    for i in range(len(l_list)):\n",
    "        b+=l_list[i]\n",
    "        if len(l_list)==2:\n",
    "            c=i+1\n",
    "            break\n",
    "    \n",
    "        elif b >=s_all:\n",
    "            c=i+1\n",
    "            break\n",
    "            \n",
    "    global wav_01\n",
    "    global wav_02\n",
    "    # 각 나눈 파장 저장        \n",
    "    wav_01 = wav[:re_time[c]]\n",
    "    wav_02 = wav[re_time[c]:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480d321d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['고생1', '했어1']\n",
      "(100, 400) (100, 400)\n",
      "['고생2', '했어2']\n",
      "(100, 400) (100, 400)\n",
      "['고생3', '했어3']\n",
      "(100, 400) (100, 400)\n",
      "['사랑1', '해요1']\n",
      "(100, 400) (100, 400)\n",
      "['사랑2', '해요2']\n",
      "(100, 400) (100, 400)\n",
      "['사랑3', '해요3']\n",
      "(100, 400) (100, 400)\n",
      "['응원1', '할게요1']\n",
      "(100, 400) (100, 400)\n",
      "['응원2', '할게요2']\n",
      "(100, 400) (100, 400)\n",
      "['응원3', '할게요3']\n",
      "(100, 400) (100, 400)\n",
      "['축하1', '해요4']\n",
      "(100, 400) (100, 400)\n",
      "['축하2', '해요5']\n",
      "(100, 400) (100, 400)\n",
      "['축하3', '해요6']\n",
      "(100, 400) (100, 400)\n",
      "['행복1', '해요7']\n",
      "(100, 400) (100, 400)\n",
      "['행복2', '해요8']\n",
      "(100, 400) (100, 400)\n",
      "['행복3', '해요9']\n",
      "(100, 400) (100, 400)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display\n",
    "import pandas as pd\n",
    "\n",
    "WAV_DIR = \"./wav/wav/\"\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "# os.listdir(TRAIN_DIR) : train 폴더로부터 wav 파일을 하나씩 읽어온다\n",
    "\n",
    "# train\n",
    "for fname in os.listdir(WAV_DIR):\n",
    "    try:\n",
    "        # 읽은 파일이 wav 파일이 아닌 경우 다음으로 넘어감\n",
    "        if \".wav\" not in fname:\n",
    "            pass\n",
    "        \n",
    "        # 라벨 데이터를 저장\n",
    "        # text는 파일 명?에서 따올 것\n",
    "        text =fname[:len(fname)-4]\n",
    "        ts = text.split(\"_\")\n",
    "        print(ts)\n",
    "        y.append(ts[0])\n",
    "        y.append(ts[1])\n",
    "        \n",
    "        # wav 파일 데이터를 읽어온다\n",
    "        wav, sr = librosa.load(WAV_DIR+fname,sr=16000)\n",
    "        \n",
    "        pretreatment(wav)\n",
    "        \n",
    "        # mfcc 전환\n",
    "        mfcc_01 = librosa.feature.mfcc(wav_01)\n",
    "        mfcc_01 = librosa.feature.mfcc(wav_01, sr=16000, n_mfcc=100, n_fft=400, hop_length=160)\n",
    "        mfcc_02 = librosa.feature.mfcc(wav_02)\n",
    "        mfcc_02 = librosa.feature.mfcc(wav_02, sr=16000, n_mfcc=100, n_fft=400, hop_length=160)      \n",
    "        \n",
    "        zero_pad_01 = np.zeros((100,400-len(mfcc_01[0])))\n",
    "        mfcc_01 = np.hstack((mfcc_01,zero_pad_01)) \n",
    "        \n",
    "        zero_pad_02 = np.zeros((100,400-len(mfcc_02[0])))\n",
    "        mfcc_02 = np.hstack((mfcc_02,zero_pad_02)) \n",
    "        \n",
    "        print(mfcc_01.shape,mfcc_02.shape)\n",
    "        \n",
    "        # wav 파일을 동일한 길이로 잘라서 특성 데이터로 저장\n",
    "        # wav 데이터의 길이를 30000으로 설정\n",
    "        #mfcc_01 = np.expand_dims(mfcc_01, -1)\n",
    "        #mfcc_02 = np.expand_dims(mfcc_02, -1)\n",
    "        \n",
    "        x.append(mfcc_01)\n",
    "        x.append(mfcc_02)\n",
    "    except:\n",
    "        print(\"파일 읽기 오류\")\n",
    "        # 다음으로 넘어간다\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3213ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "x_ex = np.expand_dims(x,-1)\n",
    "\n",
    "y = np.array(y)\n",
    "y_en = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ebeaf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 100, 400, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 400, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 200, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 200, 64)       36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 200, 128)      73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 100, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 320000)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               81920256  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                3870      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30)                120       \n",
      "=================================================================\n",
      "Total params: 82,088,278\n",
      "Trainable params: 82,087,450\n",
      "Non-trainable params: 828\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#CNN 층 : 이미지 데이터로부터 특징을 추출하는 전처리 (특성추출기)\n",
    "#일반적으로 Conv2D는 2개나 3개와 MaxPooling2D 1개로 레이어를 구성\n",
    "#컨볼루션 레이어는 데이터의 크기가 10x10 근처의 크기가 될때까지 반복\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(100,400,1), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3),  padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3),  padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # DNN에 넣어주기 위해서는 다차원 데이터를 1차원으로 펴주어야 한다\n",
    "model.add(Flatten())\n",
    "\n",
    "    # 은닉층 1차원만 들어갈 수 있어서 Flatten()을 사용해 1차원으로 펴준다.\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "    # 출력층\n",
    "model.add(Dense(len(y_en), activation=\"softmax\"))\n",
    "model.add(BatchNormalization())\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1f2cd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.5983 - accuracy: 0.2857\n",
      "Epoch 00001: accuracy improved from -inf to 0.28571, saving model to ./model4\\01-4.5201-0.2857.hdf5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.5983 - accuracy: 0.2857 - val_loss: 4.5201 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.4156 - accuracy: 0.2857\n",
      "Epoch 00002: accuracy did not improve from 0.28571\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 10.4156 - accuracy: 0.2857 - val_loss: 4.5036 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.7213 - accuracy: 0.2857\n",
      "Epoch 00003: accuracy did not improve from 0.28571\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 8.7213 - accuracy: 0.2857 - val_loss: 4.4918 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.9323 - accuracy: 0.2381\n",
      "Epoch 00004: accuracy did not improve from 0.28571\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 8.9323 - accuracy: 0.2381 - val_loss: 4.4743 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.3372 - accuracy: 0.3333\n",
      "Epoch 00005: accuracy improved from 0.28571 to 0.33333, saving model to ./model4\\05-4.4608-0.3333.hdf5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.3372 - accuracy: 0.3333 - val_loss: 4.4608 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.5459 - accuracy: 0.3810\n",
      "Epoch 00006: accuracy improved from 0.33333 to 0.38095, saving model to ./model4\\06-4.4515-0.3810.hdf5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.5459 - accuracy: 0.3810 - val_loss: 4.4515 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.6638 - accuracy: 0.2857\n",
      "Epoch 00007: accuracy did not improve from 0.38095\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 9.6638 - accuracy: 0.2857 - val_loss: 4.4421 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3750 - accuracy: 0.3333\n",
      "Epoch 00008: accuracy did not improve from 0.38095\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 9.3750 - accuracy: 0.3333 - val_loss: 4.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.1761 - accuracy: 0.4286\n",
      "Epoch 00009: accuracy improved from 0.38095 to 0.42857, saving model to ./model4\\09-4.4278-0.4286.hdf5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.1761 - accuracy: 0.4286 - val_loss: 4.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.2238 - accuracy: 0.2857\n",
      "Epoch 00010: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 10.2238 - accuracy: 0.2857 - val_loss: 4.4199 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.9524 - accuracy: 0.3810\n",
      "Epoch 00011: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 8.9524 - accuracy: 0.3810 - val_loss: 4.4092 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8979 - accuracy: 0.3810\n",
      "Epoch 00012: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 10.8979 - accuracy: 0.3810 - val_loss: 4.0937 - val_accuracy: 0.1111\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4837 - accuracy: 0.3810\n",
      "Epoch 00013: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 9.4837 - accuracy: 0.3810 - val_loss: 4.2101 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.9027 - accuracy: 0.3810\n",
      "Epoch 00014: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 10.9027 - accuracy: 0.3810 - val_loss: 4.2961 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0932 - accuracy: 0.3810\n",
      "Epoch 00015: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 10.0932 - accuracy: 0.3810 - val_loss: 4.3228 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.4817 - accuracy: 0.3810\n",
      "Epoch 00016: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 8.4817 - accuracy: 0.3810 - val_loss: 4.3240 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8548 - accuracy: 0.3810\n",
      "Epoch 00017: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 10.8548 - accuracy: 0.3810 - val_loss: 4.3390 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0134 - accuracy: 0.3810\n",
      "Epoch 00018: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 10.0134 - accuracy: 0.3810 - val_loss: 4.3541 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8272 - accuracy: 0.4286\n",
      "Epoch 00019: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 13.8272 - accuracy: 0.4286 - val_loss: 4.3741 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5244 - accuracy: 0.4286\n",
      "Epoch 00020: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 11.5244 - accuracy: 0.4286 - val_loss: 4.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0853 - accuracy: 0.2381\n",
      "Epoch 00021: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 13.0853 - accuracy: 0.2381 - val_loss: 4.4031 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.3333\n",
      "Epoch 00022: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 10.7454 - accuracy: 0.3333 - val_loss: 4.4144 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1456 - accuracy: 0.3810\n",
      "Epoch 00023: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 13.1456 - accuracy: 0.3810 - val_loss: 4.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8509 - accuracy: 0.3333\n",
      "Epoch 00024: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 13.8509 - accuracy: 0.3333 - val_loss: 4.4181 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0796 - accuracy: 0.3333\n",
      "Epoch 00025: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 13.0796 - accuracy: 0.3333 - val_loss: 4.4142 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0486 - accuracy: 0.4286\n",
      "Epoch 00026: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 13.0486 - accuracy: 0.4286 - val_loss: 4.1991 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0765 - accuracy: 0.2857\n",
      "Epoch 00027: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 13.0765 - accuracy: 0.2857 - val_loss: 4.2249 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2879 - accuracy: 0.2857\n",
      "Epoch 00028: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 12.2879 - accuracy: 0.2857 - val_loss: 4.2869 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5559 - accuracy: 0.4286\n",
      "Epoch 00029: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 11.5559 - accuracy: 0.4286 - val_loss: 4.3405 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1051 - accuracy: 0.4286\n",
      "Epoch 00030: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 13.1051 - accuracy: 0.4286 - val_loss: 4.3673 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3342 - accuracy: 0.3333\n",
      "Epoch 00031: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 12.3342 - accuracy: 0.3333 - val_loss: 4.3832 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7793 - accuracy: 0.4286\n",
      "Epoch 00032: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.7793 - accuracy: 0.4286 - val_loss: 4.3916 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3255 - accuracy: 0.3333\n",
      "Epoch 00033: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 12.3255 - accuracy: 0.3333 - val_loss: 4.3924 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3710 - accuracy: 0.3810\n",
      "Epoch 00034: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 12.3710 - accuracy: 0.3810 - val_loss: 4.3879 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.3333\n",
      "Epoch 00035: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 13.0480 - accuracy: 0.3333 - val_loss: 4.3865 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.3333\n",
      "Epoch 00036: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 12.2805 - accuracy: 0.3333 - val_loss: 4.3845 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.3333\n",
      "Epoch 00037: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 12.2805 - accuracy: 0.3333 - val_loss: 4.3813 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2103 - accuracy: 0.3333\n",
      "Epoch 00038: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 9.2103 - accuracy: 0.3333 - val_loss: 4.3833 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.3810\n",
      "Epoch 00039: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.7454 - accuracy: 0.3810 - val_loss: 4.3854 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3011 - accuracy: 0.3810\n",
      "Epoch 00040: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 12.3011 - accuracy: 0.3810 - val_loss: 4.3925 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7988 - accuracy: 0.3810\n",
      "Epoch 00041: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.7988 - accuracy: 0.3810 - val_loss: 4.3993 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.3810\n",
      "Epoch 00042: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 11.5129 - accuracy: 0.3810 - val_loss: 4.4123 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5131 - accuracy: 0.3810\n",
      "Epoch 00043: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 11.5131 - accuracy: 0.3810 - val_loss: 4.4309 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8218 - accuracy: 0.3333\n",
      "Epoch 00044: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 13.8218 - accuracy: 0.3333 - val_loss: 4.4608 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.3333\n",
      "Epoch 00045: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 13.0480 - accuracy: 0.3333 - val_loss: 4.5069 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7576 - accuracy: 0.3810\n",
      "Epoch 00046: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 10.7576 - accuracy: 0.3810 - val_loss: 4.5649 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7580 - accuracy: 0.3333\n",
      "Epoch 00047: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 10.7580 - accuracy: 0.3333 - val_loss: 4.7940 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.3810\n",
      "Epoch 00048: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 12.2805 - accuracy: 0.3810 - val_loss: 5.4713 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0829 - accuracy: 0.3333\n",
      "Epoch 00049: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 13.0829 - accuracy: 0.3333 - val_loss: 5.4640 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.4286\n",
      "Epoch 00050: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 12.2805 - accuracy: 0.4286 - val_loss: 5.4592 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8155 - accuracy: 0.3810\n",
      "Epoch 00051: accuracy did not improve from 0.42857\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 13.8155 - accuracy: 0.3810 - val_loss: 5.4549 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.4762\n",
      "Epoch 00052: accuracy improved from 0.42857 to 0.47619, saving model to ./model4\\52-5.4516-0.4762.hdf5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.7454 - accuracy: 0.4762 - val_loss: 5.4516 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2915 - accuracy: 0.2857\n",
      "Epoch 00053: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 12.2915 - accuracy: 0.2857 - val_loss: 5.4525 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.3810\n",
      "Epoch 00054: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 13.0480 - accuracy: 0.3810 - val_loss: 5.4525 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.4894 - accuracy: 0.3333\n",
      "Epoch 00055: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 12.4894 - accuracy: 0.3333 - val_loss: 5.4533 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.4286\n",
      "Epoch 00056: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 11.5129 - accuracy: 0.4286 - val_loss: 5.4534 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.3810\n",
      "Epoch 00057: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 13.0480 - accuracy: 0.3810 - val_loss: 5.4566 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.3810\n",
      "Epoch 00058: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 13.0480 - accuracy: 0.3810 - val_loss: 5.4598 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.2857\n",
      "Epoch 00059: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 13.0480 - accuracy: 0.2857 - val_loss: 5.4670 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2872 - accuracy: 0.3810\n",
      "Epoch 00060: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 12.2872 - accuracy: 0.3810 - val_loss: 5.4775 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.3333\n",
      "Epoch 00061: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 12.2805 - accuracy: 0.3333 - val_loss: 5.4907 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2821 - accuracy: 0.3810\n",
      "Epoch 00062: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 12.2821 - accuracy: 0.3810 - val_loss: 5.5028 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6832 - accuracy: 0.4286\n",
      "Epoch 00063: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 11.6832 - accuracy: 0.4286 - val_loss: 5.5157 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.3810\n",
      "Epoch 00064: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 13.0480 - accuracy: 0.3810 - val_loss: 5.5264 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0544 - accuracy: 0.4286\n",
      "Epoch 00065: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 13.0544 - accuracy: 0.4286 - val_loss: 5.5408 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2853 - accuracy: 0.4286\n",
      "Epoch 00066: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 12.2853 - accuracy: 0.4286 - val_loss: 5.5571 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.4286\n",
      "Epoch 00067: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 12.2805 - accuracy: 0.4286 - val_loss: 5.5788 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.3810\n",
      "Epoch 00068: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 13.0480 - accuracy: 0.3810 - val_loss: 5.6001 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3417 - accuracy: 0.3810\n",
      "Epoch 00069: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 12.3417 - accuracy: 0.3810 - val_loss: 5.6156 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8155 - accuracy: 0.4286\n",
      "Epoch 00070: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 13.8155 - accuracy: 0.4286 - val_loss: 5.6394 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8155 - accuracy: 0.3810\n",
      "Epoch 00071: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 13.8155 - accuracy: 0.3810 - val_loss: 5.6616 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.3333\n",
      "Epoch 00072: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 12.2805 - accuracy: 0.3333 - val_loss: 5.6857 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8155 - accuracy: 0.4286\n",
      "Epoch 00073: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 13.8155 - accuracy: 0.4286 - val_loss: 5.7133 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.2604 - accuracy: 0.3810\n",
      "Epoch 00074: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 13.2604 - accuracy: 0.3810 - val_loss: 5.7563 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.3397 - accuracy: 0.3810\n",
      "Epoch 00075: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 13.3397 - accuracy: 0.3810 - val_loss: 5.8179 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.2369 - accuracy: 0.3333\n",
      "Epoch 00076: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 13.2369 - accuracy: 0.3333 - val_loss: 5.8725 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.4567 - accuracy: 0.4286\n",
      "Epoch 00077: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 12.4567 - accuracy: 0.4286 - val_loss: 8.1545 - val_accuracy: 0.1111\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6641 - accuracy: 0.4286\n",
      "Epoch 00078: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 11.6641 - accuracy: 0.4286 - val_loss: 8.1641 - val_accuracy: 0.1111\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6798 - accuracy: 0.3810\n",
      "Epoch 00079: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 11.6798 - accuracy: 0.3810 - val_loss: 8.1761 - val_accuracy: 0.1111\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1268 - accuracy: 0.3810\n",
      "Epoch 00080: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 10.1268 - accuracy: 0.3810 - val_loss: 8.1744 - val_accuracy: 0.1111\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8926 - accuracy: 0.4286\n",
      "Epoch 00081: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 10.8926 - accuracy: 0.4286 - val_loss: 8.1381 - val_accuracy: 0.1111\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6572 - accuracy: 0.4286\n",
      "Epoch 00082: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 11.6572 - accuracy: 0.4286 - val_loss: 8.0666 - val_accuracy: 0.1111\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6637 - accuracy: 0.4286\n",
      "Epoch 00083: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 11.6637 - accuracy: 0.4286 - val_loss: 7.9819 - val_accuracy: 0.1111\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6786 - accuracy: 0.3333\n",
      "Epoch 00084: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 11.6786 - accuracy: 0.3333 - val_loss: 7.8970 - val_accuracy: 0.1111\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4116 - accuracy: 0.3810\n",
      "Epoch 00085: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 9.4116 - accuracy: 0.3810 - val_loss: 7.8570 - val_accuracy: 0.1111\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.9133 - accuracy: 0.3333\n",
      "Epoch 00086: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 10.9133 - accuracy: 0.3333 - val_loss: 7.8183 - val_accuracy: 0.1111\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.2038 - accuracy: 0.3810\n",
      "Epoch 00087: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 13.2038 - accuracy: 0.3810 - val_loss: 7.7874 - val_accuracy: 0.1111\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8829 - accuracy: 0.4286\n",
      "Epoch 00088: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.8829 - accuracy: 0.4286 - val_loss: 7.7631 - val_accuracy: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.1863 - accuracy: 0.3810\n",
      "Epoch 00089: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 11.1863 - accuracy: 0.3810 - val_loss: 7.7674 - val_accuracy: 0.1111\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6537 - accuracy: 0.4286\n",
      "Epoch 00090: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 11.6537 - accuracy: 0.4286 - val_loss: 7.7685 - val_accuracy: 0.1111\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.9462 - accuracy: 0.4286\n",
      "Epoch 00091: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 11.9462 - accuracy: 0.4286 - val_loss: 7.7751 - val_accuracy: 0.1111\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.0329 - accuracy: 0.4286\n",
      "Epoch 00092: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 11.0329 - accuracy: 0.4286 - val_loss: 7.7763 - val_accuracy: 0.1111\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.9894 - accuracy: 0.4286\n",
      "Epoch 00093: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 10.9894 - accuracy: 0.4286 - val_loss: 6.7586 - val_accuracy: 0.1111\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.9652 - accuracy: 0.3810\n",
      "Epoch 00094: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 10.9652 - accuracy: 0.3810 - val_loss: 6.6771 - val_accuracy: 0.1111\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.9573 - accuracy: 0.4286\n",
      "Epoch 00095: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 10.9573 - accuracy: 0.4286 - val_loss: 6.5855 - val_accuracy: 0.2222\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6935 - accuracy: 0.4286\n",
      "Epoch 00096: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 11.6935 - accuracy: 0.4286 - val_loss: 6.5270 - val_accuracy: 0.2222\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.7009 - accuracy: 0.4762\n",
      "Epoch 00097: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 11.7009 - accuracy: 0.4762 - val_loss: 6.4732 - val_accuracy: 0.2222\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6935 - accuracy: 0.4286\n",
      "Epoch 00098: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 8.6935 - accuracy: 0.4286 - val_loss: 6.4266 - val_accuracy: 0.2222\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1137 - accuracy: 0.4286\n",
      "Epoch 00099: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 10.1137 - accuracy: 0.4286 - val_loss: 6.3824 - val_accuracy: 0.2222\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1274 - accuracy: 0.4762\n",
      "Epoch 00100: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.1274 - accuracy: 0.4762 - val_loss: 6.3520 - val_accuracy: 0.2222\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.9065 - accuracy: 0.4762\n",
      "Epoch 00101: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 10.9065 - accuracy: 0.4762 - val_loss: 6.3310 - val_accuracy: 0.1111\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6495 - accuracy: 0.4762\n",
      "Epoch 00102: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 11.6495 - accuracy: 0.4762 - val_loss: 6.3080 - val_accuracy: 0.1111\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8775 - accuracy: 0.4762\n",
      "Epoch 00103: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 10.8775 - accuracy: 0.4762 - val_loss: 6.2994 - val_accuracy: 0.1111\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6563 - accuracy: 0.4762\n",
      "Epoch 00104: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 11.6563 - accuracy: 0.4762 - val_loss: 6.2986 - val_accuracy: 0.1111\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1105 - accuracy: 0.4762\n",
      "Epoch 00105: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.1105 - accuracy: 0.4762 - val_loss: 6.3043 - val_accuracy: 0.1111\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1093 - accuracy: 0.4286\n",
      "Epoch 00106: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 10.1093 - accuracy: 0.4286 - val_loss: 6.3152 - val_accuracy: 0.1111\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6509 - accuracy: 0.4762\n",
      "Epoch 00107: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 11.6509 - accuracy: 0.4762 - val_loss: 6.3277 - val_accuracy: 0.1111\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1115 - accuracy: 0.4762\n",
      "Epoch 00108: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.1115 - accuracy: 0.4762 - val_loss: 6.3341 - val_accuracy: 0.1111\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.9243 - accuracy: 0.3810\n",
      "Epoch 00109: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 10.9243 - accuracy: 0.3810 - val_loss: 6.3510 - val_accuracy: 0.1111\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8787 - accuracy: 0.4286\n",
      "Epoch 00110: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.8787 - accuracy: 0.4286 - val_loss: 6.3763 - val_accuracy: 0.1111\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1115 - accuracy: 0.4762\n",
      "Epoch 00111: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 10.1115 - accuracy: 0.4762 - val_loss: 6.4034 - val_accuracy: 0.1111\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6459 - accuracy: 0.4762\n",
      "Epoch 00112: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 11.6459 - accuracy: 0.4762 - val_loss: 6.4326 - val_accuracy: 0.1111\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1028 - accuracy: 0.4762\n",
      "Epoch 00113: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 10.1028 - accuracy: 0.4762 - val_loss: 6.4612 - val_accuracy: 0.1111\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8917 - accuracy: 0.4286\n",
      "Epoch 00114: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 10.8917 - accuracy: 0.4286 - val_loss: 6.4976 - val_accuracy: 0.1111\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8726 - accuracy: 0.4762\n",
      "Epoch 00115: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 10.8726 - accuracy: 0.4762 - val_loss: 6.5332 - val_accuracy: 0.1111\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6434 - accuracy: 0.4762\n",
      "Epoch 00116: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 11.6434 - accuracy: 0.4762 - val_loss: 6.5684 - val_accuracy: 0.1111\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3375 - accuracy: 0.4762\n",
      "Epoch 00117: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 9.3375 - accuracy: 0.4762 - val_loss: 6.6014 - val_accuracy: 0.1111\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6390 - accuracy: 0.4762\n",
      "Epoch 00118: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 11.6390 - accuracy: 0.4762 - val_loss: 6.6418 - val_accuracy: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6417 - accuracy: 0.4762\n",
      "Epoch 00119: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 11.6417 - accuracy: 0.4762 - val_loss: 6.6853 - val_accuracy: 0.1111\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.0121 - accuracy: 0.4762\n",
      "Epoch 00120: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 11.0121 - accuracy: 0.4762 - val_loss: 6.7253 - val_accuracy: 0.1111\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0979 - accuracy: 0.4762\n",
      "Epoch 00121: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 10.0979 - accuracy: 0.4762 - val_loss: 6.7676 - val_accuracy: 0.1111\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8763 - accuracy: 0.4762\n",
      "Epoch 00122: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 10.8763 - accuracy: 0.4762 - val_loss: 6.8127 - val_accuracy: 0.1111\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6398 - accuracy: 0.4762\n",
      "Epoch 00123: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 11.6398 - accuracy: 0.4762 - val_loss: 6.8647 - val_accuracy: 0.1111\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6359 - accuracy: 0.4762\n",
      "Epoch 00124: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 11.6359 - accuracy: 0.4762 - val_loss: 6.9137 - val_accuracy: 0.1111\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8777 - accuracy: 0.4762\n",
      "Epoch 00125: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 10.8777 - accuracy: 0.4762 - val_loss: 6.9780 - val_accuracy: 0.1111\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.0515 - accuracy: 0.4762\n",
      "Epoch 00126: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 11.0515 - accuracy: 0.4762 - val_loss: 7.0538 - val_accuracy: 0.1111\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.0330 - accuracy: 0.4762\n",
      "Epoch 00127: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 11.0330 - accuracy: 0.4762 - val_loss: 6.9777 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1407 - accuracy: 0.4762\n",
      "Epoch 00128: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 10.1407 - accuracy: 0.4762 - val_loss: 6.9786 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.9467 - accuracy: 0.4286\n",
      "Epoch 00129: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 10.9467 - accuracy: 0.4286 - val_loss: 6.9246 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6485 - accuracy: 0.4762\n",
      "Epoch 00130: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 11.6485 - accuracy: 0.4762 - val_loss: 6.9200 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8798 - accuracy: 0.4762\n",
      "Epoch 00131: accuracy did not improve from 0.47619\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 10.8798 - accuracy: 0.4762 - val_loss: 6.9278 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.1876 - accuracy: 0.5238\n",
      "Epoch 00132: accuracy improved from 0.47619 to 0.52381, saving model to ./model4\\132-8.1614-0.5238.hdf5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.1876 - accuracy: 0.5238 - val_loss: 8.1614 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.2230 - accuracy: 0.5238\n",
      "Epoch 00133: accuracy did not improve from 0.52381\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 10.2230 - accuracy: 0.5238 - val_loss: 8.5500 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6616 - accuracy: 0.5714\n",
      "Epoch 00134: accuracy improved from 0.52381 to 0.57143, saving model to ./model4\\134-10.4810-0.5714.hdf5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8.6616 - accuracy: 0.5714 - val_loss: 10.4810 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.9132 - accuracy: 0.5238\n",
      "Epoch 00135: accuracy did not improve from 0.57143\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 10.9132 - accuracy: 0.5238 - val_loss: 13.2998 - val_accuracy: 0.1111\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8971 - accuracy: 0.6190\n",
      "Epoch 00136: accuracy improved from 0.57143 to 0.61905, saving model to ./model4\\136-15.1470-0.6190.hdf5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.8971 - accuracy: 0.6190 - val_loss: 15.1470 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.4246 - accuracy: 0.6190\n",
      "Epoch 00137: accuracy did not improve from 0.61905\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 12.4246 - accuracy: 0.6190 - val_loss: 13.4420 - val_accuracy: 0.1111\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8776 - accuracy: 0.6190\n",
      "Epoch 00138: accuracy did not improve from 0.61905\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 10.8776 - accuracy: 0.6190 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3918 - accuracy: 0.5714\n",
      "Epoch 00139: accuracy did not improve from 0.61905\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 12.3918 - accuracy: 0.5714 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0678 - accuracy: 0.6190\n",
      "Epoch 00140: accuracy did not improve from 0.61905\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.0678 - accuracy: 0.6190 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.5714\n",
      "Epoch 00141: accuracy did not improve from 0.61905\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 11.5129 - accuracy: 0.5714 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5799 - accuracy: 0.5238\n",
      "Epoch 00142: accuracy did not improve from 0.61905\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 11.5799 - accuracy: 0.5238 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.7939 - accuracy: 0.5238\n",
      "Epoch 00143: accuracy did not improve from 0.61905\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 8.7939 - accuracy: 0.5238 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1818 - accuracy: 0.5714\n",
      "Epoch 00144: accuracy did not improve from 0.61905\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 10.1818 - accuracy: 0.5714 - val_loss: 13.0145 - val_accuracy: 0.1111\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4440 - accuracy: 0.5714\n",
      "Epoch 00145: accuracy did not improve from 0.61905\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 9.4440 - accuracy: 0.5714 - val_loss: 12.8135 - val_accuracy: 0.1111\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3475 - accuracy: 0.6190\n",
      "Epoch 00146: accuracy did not improve from 0.61905\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 9.3475 - accuracy: 0.6190 - val_loss: 12.7421 - val_accuracy: 0.1111\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2191 - accuracy: 0.5714\n",
      "Epoch 00147: accuracy did not improve from 0.61905\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 9.2191 - accuracy: 0.5714 - val_loss: 12.7396 - val_accuracy: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0018 - accuracy: 0.6667\n",
      "Epoch 00148: accuracy improved from 0.61905 to 0.66667, saving model to ./model4\\148-12.7946-0.6667.hdf5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.0018 - accuracy: 0.6667 - val_loss: 12.7946 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5389 - accuracy: 0.5714\n",
      "Epoch 00149: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 11.5389 - accuracy: 0.5714 - val_loss: 12.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5752 - accuracy: 0.5714\n",
      "Epoch 00150: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 8.5752 - accuracy: 0.5714 - val_loss: 12.9562 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7782 - accuracy: 0.6190\n",
      "Epoch 00151: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 10.7782 - accuracy: 0.6190 - val_loss: 13.0162 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9802 - accuracy: 0.6190\n",
      "Epoch 00152: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 9.9802 - accuracy: 0.6190 - val_loss: 11.9868 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5132 - accuracy: 0.5238\n",
      "Epoch 00153: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 11.5132 - accuracy: 0.5238 - val_loss: 11.8577 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.6190\n",
      "Epoch 00154: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 12.2805 - accuracy: 0.6190 - val_loss: 11.8336 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7950 - accuracy: 0.5238\n",
      "Epoch 00155: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 10.7950 - accuracy: 0.5238 - val_loss: 11.8120 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6190\n",
      "Epoch 00156: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 10.7454 - accuracy: 0.6190 - val_loss: 11.7957 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7684 - accuracy: 0.5714\n",
      "Epoch 00157: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 10.7684 - accuracy: 0.5714 - val_loss: 11.8157 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.5714\n",
      "Epoch 00158: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 12.2805 - accuracy: 0.5714 - val_loss: 11.8764 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.5714\n",
      "Epoch 00159: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 11.5129 - accuracy: 0.5714 - val_loss: 12.0821 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.6190\n",
      "Epoch 00160: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 11.5129 - accuracy: 0.6190 - val_loss: 12.9273 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.5714\n",
      "Epoch 00161: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 9.9779 - accuracy: 0.5714 - val_loss: 12.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.6190\n",
      "Epoch 00162: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 12.2805 - accuracy: 0.6190 - val_loss: 12.8992 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.5714\n",
      "Epoch 00163: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 11.5129 - accuracy: 0.5714 - val_loss: 12.8880 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.6190\n",
      "Epoch 00164: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 11.5129 - accuracy: 0.6190 - val_loss: 12.8799 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.6032 - accuracy: 0.6190\n",
      "Epoch 00165: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 9.6032 - accuracy: 0.6190 - val_loss: 12.9223 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1163 - accuracy: 0.6190\n",
      "Epoch 00166: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 10.1163 - accuracy: 0.6190 - val_loss: 11.1775 - val_accuracy: 0.1111\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6608 - accuracy: 0.5714\n",
      "Epoch 00167: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 11.6608 - accuracy: 0.5714 - val_loss: 13.0571 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3882 - accuracy: 0.6190\n",
      "Epoch 00168: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 9.3882 - accuracy: 0.6190 - val_loss: 13.1526 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6068 - accuracy: 0.5714\n",
      "Epoch 00169: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 8.6068 - accuracy: 0.5714 - val_loss: 13.1792 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5743 - accuracy: 0.6190\n",
      "Epoch 00170: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 8.5743 - accuracy: 0.6190 - val_loss: 13.2290 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3405 - accuracy: 0.5238\n",
      "Epoch 00171: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 9.3405 - accuracy: 0.5238 - val_loss: 13.1968 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3906 - accuracy: 0.6190\n",
      "Epoch 00172: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 9.3906 - accuracy: 0.6190 - val_loss: 12.3358 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8923 - accuracy: 0.5238\n",
      "Epoch 00173: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 10.8923 - accuracy: 0.5238 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1052 - accuracy: 0.6190\n",
      "Epoch 00174: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 10.1052 - accuracy: 0.6190 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1073 - accuracy: 0.5238\n",
      "Epoch 00175: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 10.1073 - accuracy: 0.5238 - val_loss: 12.8232 - val_accuracy: 0.1111\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8715 - accuracy: 0.6190\n",
      "Epoch 00176: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 10.8715 - accuracy: 0.6190 - val_loss: 12.6538 - val_accuracy: 0.1111\n",
      "Epoch 177/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 9.3447 - accuracy: 0.6190\n",
      "Epoch 00177: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 9.3447 - accuracy: 0.6190 - val_loss: 12.5534 - val_accuracy: 0.1111\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3460 - accuracy: 0.6190\n",
      "Epoch 00178: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 9.3460 - accuracy: 0.6190 - val_loss: 12.5363 - val_accuracy: 0.2222\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8827 - accuracy: 0.5714\n",
      "Epoch 00179: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 10.8827 - accuracy: 0.5714 - val_loss: 12.5363 - val_accuracy: 0.2222\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8662 - accuracy: 0.6667\n",
      "Epoch 00180: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.8662 - accuracy: 0.6667 - val_loss: 12.5363 - val_accuracy: 0.2222\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1066 - accuracy: 0.5714\n",
      "Epoch 00181: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 10.1066 - accuracy: 0.5714 - val_loss: 12.5363 - val_accuracy: 0.2222\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5640 - accuracy: 0.6190\n",
      "Epoch 00182: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 8.5640 - accuracy: 0.6190 - val_loss: 12.5363 - val_accuracy: 0.1111\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8815 - accuracy: 0.6190\n",
      "Epoch 00183: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 10.8815 - accuracy: 0.6190 - val_loss: 11.4420 - val_accuracy: 0.1111\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5615 - accuracy: 0.6190\n",
      "Epoch 00184: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 8.5615 - accuracy: 0.6190 - val_loss: 11.3461 - val_accuracy: 0.1111\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5680 - accuracy: 0.5714\n",
      "Epoch 00185: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 8.5680 - accuracy: 0.5714 - val_loss: 11.3100 - val_accuracy: 0.1111\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8777 - accuracy: 0.6190\n",
      "Epoch 00186: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 10.8777 - accuracy: 0.6190 - val_loss: 11.2967 - val_accuracy: 0.1111\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3230 - accuracy: 0.6667\n",
      "Epoch 00187: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 9.3230 - accuracy: 0.6667 - val_loss: 11.2864 - val_accuracy: 0.1111\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0928 - accuracy: 0.6667\n",
      "Epoch 00188: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 10.0928 - accuracy: 0.6667 - val_loss: 11.2741 - val_accuracy: 0.1111\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3240 - accuracy: 0.6667\n",
      "Epoch 00189: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 9.3240 - accuracy: 0.6667 - val_loss: 11.2660 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8602 - accuracy: 0.6190\n",
      "Epoch 00190: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 10.8602 - accuracy: 0.6190 - val_loss: 11.2584 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0881 - accuracy: 0.6667\n",
      "Epoch 00191: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 10.0881 - accuracy: 0.6667 - val_loss: 11.2578 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1015 - accuracy: 0.5238\n",
      "Epoch 00192: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 10.1015 - accuracy: 0.5238 - val_loss: 11.2660 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0892 - accuracy: 0.6667\n",
      "Epoch 00193: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 10.0892 - accuracy: 0.6667 - val_loss: 11.2725 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0916 - accuracy: 0.6667\n",
      "Epoch 00194: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 10.0916 - accuracy: 0.6667 - val_loss: 11.2816 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0813 - accuracy: 0.6667\n",
      "Epoch 00195: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 10.0813 - accuracy: 0.6667 - val_loss: 11.2857 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4273 - accuracy: 0.6190\n",
      "Epoch 00196: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 9.4273 - accuracy: 0.6190 - val_loss: 10.2316 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8686 - accuracy: 0.5714\n",
      "Epoch 00197: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 10.8686 - accuracy: 0.5714 - val_loss: 10.1335 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3205 - accuracy: 0.6190\n",
      "Epoch 00198: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 9.3205 - accuracy: 0.6190 - val_loss: 10.0844 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.1394 - accuracy: 0.6190\n",
      "Epoch 00199: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 10.1394 - accuracy: 0.6190 - val_loss: 10.0645 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.7058 - accuracy: 0.6667\n",
      "Epoch 00200: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 8.7058 - accuracy: 0.6667 - val_loss: 10.1019 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.5009 - accuracy: 0.6190\n",
      "Epoch 00201: accuracy did not improve from 0.66667\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 9.5009 - accuracy: 0.6190 - val_loss: 10.1447 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8204 - accuracy: 0.7143\n",
      "Epoch 00202: accuracy improved from 0.66667 to 0.71429, saving model to ./model4\\202-10.1958-0.7143.hdf5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10.8204 - accuracy: 0.7143 - val_loss: 10.1958 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00203: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 10.2710 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2135 - accuracy: 0.7143\n",
      "Epoch 00204: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 9.2135 - accuracy: 0.7143 - val_loss: 10.3495 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00205: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 10.4514 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 10.7460 - accuracy: 0.6667\n",
      "Epoch 00206: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 10.7460 - accuracy: 0.6667 - val_loss: 10.5921 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6667\n",
      "Epoch 00207: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 10.7454 - accuracy: 0.6667 - val_loss: 10.4305 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00208: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 10.3605 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00209: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 10.3160 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00210: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 10.2749 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00211: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 10.2440 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7480 - accuracy: 0.6667\n",
      "Epoch 00212: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 10.7480 - accuracy: 0.6667 - val_loss: 9.3545 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00213: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 9.3079 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6667\n",
      "Epoch 00214: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.7454 - accuracy: 0.6667 - val_loss: 9.4019 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2103 - accuracy: 0.7143\n",
      "Epoch 00215: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 9.2103 - accuracy: 0.7143 - val_loss: 10.3577 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2519 - accuracy: 0.7143\n",
      "Epoch 00216: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 9.2519 - accuracy: 0.7143 - val_loss: 10.3030 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5140 - accuracy: 0.7143\n",
      "Epoch 00217: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 11.5140 - accuracy: 0.7143 - val_loss: 10.2605 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7504 - accuracy: 0.7143\n",
      "Epoch 00218: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 10.7504 - accuracy: 0.7143 - val_loss: 10.2228 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.6667\n",
      "Epoch 00219: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 9.9779 - accuracy: 0.6667 - val_loss: 10.1860 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00220: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 10.1533 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00221: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 10.1276 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2103 - accuracy: 0.6667\n",
      "Epoch 00222: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 9.2103 - accuracy: 0.6667 - val_loss: 10.1117 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.6667\n",
      "Epoch 00223: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 9.9779 - accuracy: 0.6667 - val_loss: 9.2148 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9849 - accuracy: 0.6667\n",
      "Epoch 00224: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 9.9849 - accuracy: 0.6667 - val_loss: 9.1799 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6667\n",
      "Epoch 00225: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 10.7454 - accuracy: 0.6667 - val_loss: 9.1260 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00226: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 9.1299 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00227: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 9.1695 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5203 - accuracy: 0.6667\n",
      "Epoch 00228: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 8.5203 - accuracy: 0.6667 - val_loss: 10.0430 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9887 - accuracy: 0.7143\n",
      "Epoch 00229: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 9.9887 - accuracy: 0.7143 - val_loss: 10.0290 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00230: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 10.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00231: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 10.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00232: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 9.9980 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9815 - accuracy: 0.7143\n",
      "Epoch 00233: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 9.9815 - accuracy: 0.7143 - val_loss: 9.9852 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2103 - accuracy: 0.7143\n",
      "Epoch 00234: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 9.2103 - accuracy: 0.7143 - val_loss: 9.9731 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00235: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 9.9609 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00236: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 9.9503 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00237: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 9.9419 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.4428 - accuracy: 0.7143\n",
      "Epoch 00238: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 8.4428 - accuracy: 0.7143 - val_loss: 9.9335 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00239: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 9.0993 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.6667\n",
      "Epoch 00240: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 11.5129 - accuracy: 0.6667 - val_loss: 9.0073 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00241: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.9436 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5135 - accuracy: 0.7143\n",
      "Epoch 00242: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 11.5135 - accuracy: 0.7143 - val_loss: 8.9242 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.7143\n",
      "Epoch 00243: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 12.2805 - accuracy: 0.7143 - val_loss: 8.9105 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00244: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.9130 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6667\n",
      "Epoch 00245: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 10.7454 - accuracy: 0.6667 - val_loss: 8.8996 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00246: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.8804 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00247: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 8.8524 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00248: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.8502 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00249: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.8280 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00250: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.8056 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00251: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.7892 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6667\n",
      "Epoch 00252: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 10.7454 - accuracy: 0.6667 - val_loss: 8.7753 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00253: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 8.7637 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00254: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.7484 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00255: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.7347 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00256: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.7178 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00257: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00258: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.6975 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5146 - accuracy: 0.6667\n",
      "Epoch 00259: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 11.5146 - accuracy: 0.6667 - val_loss: 8.6993 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00260: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 8.6947 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00261: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.6849 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.7143\n",
      "Epoch 00262: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 12.2805 - accuracy: 0.7143 - val_loss: 8.6778 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6667\n",
      "Epoch 00263: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 10.7454 - accuracy: 0.6667 - val_loss: 8.6742 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.7143\n",
      "Epoch 00264: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 12.2805 - accuracy: 0.7143 - val_loss: 8.6754 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.7143\n",
      "Epoch 00265: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 12.2805 - accuracy: 0.7143 - val_loss: 8.6707 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9917 - accuracy: 0.6190\n",
      "Epoch 00266: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 9.9917 - accuracy: 0.6190 - val_loss: 8.6390 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00267: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.6222 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00268: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.6128 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.7143\n",
      "Epoch 00269: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 12.2805 - accuracy: 0.7143 - val_loss: 8.6054 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.7143\n",
      "Epoch 00270: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 13.0480 - accuracy: 0.7143 - val_loss: 8.6023 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.6667\n",
      "Epoch 00271: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 11.5129 - accuracy: 0.6667 - val_loss: 8.5948 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00272: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.5867 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00273: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.5829 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00274: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 8.5789 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00275: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.5752 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00276: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 8.5722 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6190\n",
      "Epoch 00277: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.7454 - accuracy: 0.6190 - val_loss: 8.5705 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2103 - accuracy: 0.7143\n",
      "Epoch 00278: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 9.2103 - accuracy: 0.7143 - val_loss: 8.5667 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2103 - accuracy: 0.7143\n",
      "Epoch 00279: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 9.2103 - accuracy: 0.7143 - val_loss: 8.5636 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00280: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.5621 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2203 - accuracy: 0.7143\n",
      "Epoch 00281: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 9.2203 - accuracy: 0.7143 - val_loss: 8.5617 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2103 - accuracy: 0.6667\n",
      "Epoch 00282: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 9.2103 - accuracy: 0.6667 - val_loss: 8.5571 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00283: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 8.5523 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2103 - accuracy: 0.6190\n",
      "Epoch 00284: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 9.2103 - accuracy: 0.6190 - val_loss: 8.5506 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.6667\n",
      "Epoch 00285: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 9.9779 - accuracy: 0.6667 - val_loss: 8.5501 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6667\n",
      "Epoch 00286: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 10.7454 - accuracy: 0.6667 - val_loss: 8.5522 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00287: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.5519 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00288: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.5506 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6667\n",
      "Epoch 00289: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 10.7454 - accuracy: 0.6667 - val_loss: 8.5528 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0139 - accuracy: 0.7143\n",
      "Epoch 00290: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.0139 - accuracy: 0.7143 - val_loss: 8.5605 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00291: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.5684 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00292: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.5808 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.6667\n",
      "Epoch 00293: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 9.9779 - accuracy: 0.6667 - val_loss: 8.5850 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00294: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.5937 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.6667\n",
      "Epoch 00295: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 12.2805 - accuracy: 0.6667 - val_loss: 8.6037 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.6667\n",
      "Epoch 00296: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 11.5129 - accuracy: 0.6667 - val_loss: 8.6075 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00297: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.6137 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00298: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.6193 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.6667\n",
      "Epoch 00299: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 11.5129 - accuracy: 0.6667 - val_loss: 8.6296 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.6667\n",
      "Epoch 00300: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 12.2805 - accuracy: 0.6667 - val_loss: 8.6323 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2103 - accuracy: 0.7143\n",
      "Epoch 00301: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 9.2103 - accuracy: 0.7143 - val_loss: 8.6363 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.6667\n",
      "Epoch 00302: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 11.5129 - accuracy: 0.6667 - val_loss: 8.6442 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7501 - accuracy: 0.7143\n",
      "Epoch 00303: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 10.7501 - accuracy: 0.7143 - val_loss: 8.6521 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00304: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.6565 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00305: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.6654 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00306: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 8.6795 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.6667\n",
      "Epoch 00307: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 9.9779 - accuracy: 0.6667 - val_loss: 8.6942 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00308: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 8.6992 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00309: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.7103 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8291 - accuracy: 0.7143\n",
      "Epoch 00310: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 13.8291 - accuracy: 0.7143 - val_loss: 8.7110 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00311: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.7037 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00312: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.7089 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00313: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 8.7154 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5130 - accuracy: 0.6667\n",
      "Epoch 00314: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 11.5130 - accuracy: 0.6667 - val_loss: 8.7127 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6667\n",
      "Epoch 00315: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.7454 - accuracy: 0.6667 - val_loss: 8.7281 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7468 - accuracy: 0.7143\n",
      "Epoch 00316: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 10.7468 - accuracy: 0.7143 - val_loss: 8.7200 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6667\n",
      "Epoch 00317: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 10.7454 - accuracy: 0.6667 - val_loss: 8.7179 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.6667\n",
      "Epoch 00318: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 9.9779 - accuracy: 0.6667 - val_loss: 8.7178 - val_accuracy: 0.1111\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00319: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.7183 - val_accuracy: 0.1111\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00320: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.7326 - val_accuracy: 0.1111\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00321: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.7309 - val_accuracy: 0.1111\n",
      "Epoch 322/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00322: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.7457 - val_accuracy: 0.1111\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5207 - accuracy: 0.7143\n",
      "Epoch 00323: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 11.5207 - accuracy: 0.7143 - val_loss: 8.7733 - val_accuracy: 0.1111\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00324: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 8.7841 - val_accuracy: 0.1111\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.7143\n",
      "Epoch 00325: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 12.2805 - accuracy: 0.7143 - val_loss: 8.8039 - val_accuracy: 0.1111\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00326: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 8.8496 - val_accuracy: 0.1111\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.6667\n",
      "Epoch 00327: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.7454 - accuracy: 0.6667 - val_loss: 8.9299 - val_accuracy: 0.1111\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00328: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 9.9268 - val_accuracy: 0.1111\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00329: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 9.9251 - val_accuracy: 0.1111\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.2103 - accuracy: 0.7143\n",
      "Epoch 00330: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 9.2103 - accuracy: 0.7143 - val_loss: 9.9228 - val_accuracy: 0.1111\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00331: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 9.9203 - val_accuracy: 0.1111\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00332: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 9.9198 - val_accuracy: 0.1111\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00333: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 9.9187 - val_accuracy: 0.1111\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7568 - accuracy: 0.7143\n",
      "Epoch 00334: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 10.7568 - accuracy: 0.7143 - val_loss: 9.9106 - val_accuracy: 0.1111\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.7143\n",
      "Epoch 00335: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 12.2805 - accuracy: 0.7143 - val_loss: 9.9042 - val_accuracy: 0.1111\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.6667\n",
      "Epoch 00336: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 11.5129 - accuracy: 0.6667 - val_loss: 9.8970 - val_accuracy: 0.1111\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00337: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 9.8906 - val_accuracy: 0.1111\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00338: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 9.8857 - val_accuracy: 0.1111\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00339: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 9.8819 - val_accuracy: 0.1111\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9779 - accuracy: 0.7143\n",
      "Epoch 00340: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 9.9779 - accuracy: 0.7143 - val_loss: 9.8776 - val_accuracy: 0.1111\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00341: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 9.8739 - val_accuracy: 0.1111\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.3056 - accuracy: 0.7143\n",
      "Epoch 00342: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 9.3056 - accuracy: 0.7143 - val_loss: 9.8619 - val_accuracy: 0.1111\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.7143\n",
      "Epoch 00343: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 10.7454 - accuracy: 0.7143 - val_loss: 9.8538 - val_accuracy: 0.1111\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.7143\n",
      "Epoch 00344: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 11.5129 - accuracy: 0.7143 - val_loss: 8.9530 - val_accuracy: 0.1111\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.6667\n",
      "Epoch 00345: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 11.5129 - accuracy: 0.6667 - val_loss: 8.6794 - val_accuracy: 0.1111\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.2675 - accuracy: 0.7143\n",
      "Epoch 00346: accuracy did not improve from 0.71429\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 10.2675 - accuracy: 0.7143 - val_loss: 8.3690 - val_accuracy: 0.1111\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9992 - accuracy: 0.7619\n",
      "Epoch 00347: accuracy improved from 0.71429 to 0.76190, saving model to ./model4\\347-8.2445-0.7619.hdf5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9.9992 - accuracy: 0.7619 - val_loss: 8.2445 - val_accuracy: 0.1111\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0235 - accuracy: 0.6667\n",
      "Epoch 00348: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 10.0235 - accuracy: 0.6667 - val_loss: 8.1980 - val_accuracy: 0.1111\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.4428 - accuracy: 0.7143\n",
      "Epoch 00349: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 8.4428 - accuracy: 0.7143 - val_loss: 6.4913 - val_accuracy: 0.1111\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.9901 - accuracy: 0.6667\n",
      "Epoch 00350: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 9.9901 - accuracy: 0.6667 - val_loss: 6.7320 - val_accuracy: 0.1111\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4030 - accuracy: 0.6190\n",
      "Epoch 00351: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 9.4030 - accuracy: 0.6190 - val_loss: 7.9880 - val_accuracy: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.5826 - accuracy: 0.5714\n",
      "Epoch 00352: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 10.5826 - accuracy: 0.5714 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.6660 - accuracy: 0.6190\n",
      "Epoch 00353: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 8.6660 - accuracy: 0.6190 - val_loss: 14.7360 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.0836 - accuracy: 0.5714\n",
      "Epoch 00354: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 8.0836 - accuracy: 0.5714 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.1470 - accuracy: 0.6190\n",
      "Epoch 00355: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 8.1470 - accuracy: 0.6190 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.2206 - accuracy: 0.6190\n",
      "Epoch 00356: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 8.2206 - accuracy: 0.6190 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.8538 - accuracy: 0.6667\n",
      "Epoch 00357: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 6.8538 - accuracy: 0.6667 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9569 - accuracy: 0.5714\n",
      "Epoch 00358: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 5.9569 - accuracy: 0.5714 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8109 - accuracy: 0.6190\n",
      "Epoch 00359: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 5.8109 - accuracy: 0.6190 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8283 - accuracy: 0.6667\n",
      "Epoch 00360: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 5.8283 - accuracy: 0.6667 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.2174 - accuracy: 0.4762\n",
      "Epoch 00361: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 6.2174 - accuracy: 0.4762 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.6618 - accuracy: 0.4762\n",
      "Epoch 00362: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 6.6618 - accuracy: 0.4762 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1506 - accuracy: 0.5714\n",
      "Epoch 00363: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 5.1506 - accuracy: 0.5714 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9795 - accuracy: 0.6667\n",
      "Epoch 00364: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 5.9795 - accuracy: 0.6667 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8032 - accuracy: 0.5238\n",
      "Epoch 00365: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 5.8032 - accuracy: 0.5238 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.3794 - accuracy: 0.5714\n",
      "Epoch 00366: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 7.3794 - accuracy: 0.5714 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8520 - accuracy: 0.5238\n",
      "Epoch 00367: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 5.8520 - accuracy: 0.5238 - val_loss: 14.6032 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.7271 - accuracy: 0.4762\n",
      "Epoch 00368: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 6.7271 - accuracy: 0.4762 - val_loss: 14.4888 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.0829 - accuracy: 0.3333\n",
      "Epoch 00369: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 6.0829 - accuracy: 0.3333 - val_loss: 14.4417 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1304 - accuracy: 0.2857\n",
      "Epoch 00370: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 4.1304 - accuracy: 0.2857 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.0555 - accuracy: 0.1905\n",
      "Epoch 00371: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 6.0555 - accuracy: 0.1905 - val_loss: 14.3272 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.3810 - accuracy: 0.3333\n",
      "Epoch 00372: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 6.3810 - accuracy: 0.3333 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.5413 - accuracy: 0.4286\n",
      "Epoch 00373: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 7.5413 - accuracy: 0.4286 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.6689 - accuracy: 0.1905\n",
      "Epoch 00374: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 5.6689 - accuracy: 0.1905 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.3706 - accuracy: 0.1429\n",
      "Epoch 00375: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 5.3706 - accuracy: 0.1429 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7528 - accuracy: 0.2857\n",
      "Epoch 00376: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 5.7528 - accuracy: 0.2857 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8712 - accuracy: 0.3333\n",
      "Epoch 00377: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 5.8712 - accuracy: 0.3333 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.7585 - accuracy: 0.2381\n",
      "Epoch 00378: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 5.7585 - accuracy: 0.2381 - val_loss: 12.5385 - val_accuracy: 0.1111\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.9675 - accuracy: 0.2857\n",
      "Epoch 00379: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 3.9675 - accuracy: 0.2857 - val_loss: 10.8788 - val_accuracy: 0.1111\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0999 - accuracy: 0.2857\n",
      "Epoch 00380: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 5.0999 - accuracy: 0.2857 - val_loss: 9.2242 - val_accuracy: 0.1111\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7608 - accuracy: 0.2857\n",
      "Epoch 00381: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 3.7608 - accuracy: 0.2857 - val_loss: 9.3679 - val_accuracy: 0.1111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6002 - accuracy: 0.3810\n",
      "Epoch 00382: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 3.6002 - accuracy: 0.3810 - val_loss: 9.4371 - val_accuracy: 0.1111\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.4953 - accuracy: 0.3810\n",
      "Epoch 00383: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 4.4953 - accuracy: 0.3810 - val_loss: 9.4661 - val_accuracy: 0.1111\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1169 - accuracy: 0.3810\n",
      "Epoch 00384: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 5.1169 - accuracy: 0.3810 - val_loss: 9.4797 - val_accuracy: 0.1111\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.2310 - accuracy: 0.4762\n",
      "Epoch 00385: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 4.2310 - accuracy: 0.4762 - val_loss: 9.4952 - val_accuracy: 0.1111\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0164 - accuracy: 0.3810\n",
      "Epoch 00386: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 5.0164 - accuracy: 0.3810 - val_loss: 9.5036 - val_accuracy: 0.1111\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.0388 - accuracy: 0.3810\n",
      "Epoch 00387: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 5.0388 - accuracy: 0.3810 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1198 - accuracy: 0.3333\n",
      "Epoch 00388: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 4.1198 - accuracy: 0.3333 - val_loss: 11.3412 - val_accuracy: 0.1111\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.4233 - accuracy: 0.3810\n",
      "Epoch 00389: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 3.4233 - accuracy: 0.3810 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.5195 - accuracy: 0.4762\n",
      "Epoch 00390: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 3.5195 - accuracy: 0.4762 - val_loss: 14.3272 - val_accuracy: 0.1111\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.8320 - accuracy: 0.4286\n",
      "Epoch 00391: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.8320 - accuracy: 0.4286 - val_loss: 9.5190 - val_accuracy: 0.1111\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.1418 - accuracy: 0.4286\n",
      "Epoch 00392: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 4.1418 - accuracy: 0.4286 - val_loss: 9.5133 - val_accuracy: 0.1111\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.2579 - accuracy: 0.4762\n",
      "Epoch 00393: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 3.2579 - accuracy: 0.4762 - val_loss: 9.5383 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.5614 - accuracy: 0.5238\n",
      "Epoch 00394: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 2.5614 - accuracy: 0.5238 - val_loss: 9.5700 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7814 - accuracy: 0.5238\n",
      "Epoch 00395: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 4.7814 - accuracy: 0.5238 - val_loss: 9.5829 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.7529 - accuracy: 0.6190\n",
      "Epoch 00396: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 4.7529 - accuracy: 0.6190 - val_loss: 9.7280 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.9692 - accuracy: 0.5714\n",
      "Epoch 00397: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 3.9692 - accuracy: 0.5714 - val_loss: 10.0761 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.4554 - accuracy: 0.6190\n",
      "Epoch 00398: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 2.4554 - accuracy: 0.6190 - val_loss: 11.3910 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8614 - accuracy: 0.5714\n",
      "Epoch 00399: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 3.8614 - accuracy: 0.5714 - val_loss: 16.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.9476 - accuracy: 0.5714\n",
      "Epoch 00400: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.9476 - accuracy: 0.5714 - val_loss: 5.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0869 - accuracy: 0.6190\n",
      "Epoch 00401: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 3.0869 - accuracy: 0.6190 - val_loss: 5.0208 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.0188 - accuracy: 0.5714\n",
      "Epoch 00402: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.0188 - accuracy: 0.5714 - val_loss: 4.7706 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.6451 - accuracy: 0.5714\n",
      "Epoch 00403: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 4.6451 - accuracy: 0.5714 - val_loss: 6.2828 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.8021 - accuracy: 0.5714\n",
      "Epoch 00404: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 3.8021 - accuracy: 0.5714 - val_loss: 11.4359 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3760 - accuracy: 0.5714\n",
      "Epoch 00405: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 1.3760 - accuracy: 0.5714 - val_loss: 13.2145 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.1965 - accuracy: 0.6190\n",
      "Epoch 00406: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.1965 - accuracy: 0.6190 - val_loss: 13.2177 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6901 - accuracy: 0.6190\n",
      "Epoch 00407: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 3.6901 - accuracy: 0.6190 - val_loss: 13.2209 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2019 - accuracy: 0.5714\n",
      "Epoch 00408: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 2.2019 - accuracy: 0.5714 - val_loss: 13.2237 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9588 - accuracy: 0.6667\n",
      "Epoch 00409: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 5.9588 - accuracy: 0.6667 - val_loss: 13.2266 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3934 - accuracy: 0.6190\n",
      "Epoch 00410: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 4.3934 - accuracy: 0.6190 - val_loss: 13.2295 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3984 - accuracy: 0.5714\n",
      "Epoch 00411: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 4.3984 - accuracy: 0.5714 - val_loss: 13.2325 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.4243 - accuracy: 0.4286\n",
      "Epoch 00412: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 4.4243 - accuracy: 0.4286 - val_loss: 11.4870 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.7208 - accuracy: 0.5714\n",
      "Epoch 00413: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 6.7208 - accuracy: 0.5714 - val_loss: 11.5699 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9220 - accuracy: 0.6190\n",
      "Epoch 00414: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 5.9220 - accuracy: 0.6190 - val_loss: 11.6182 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3913 - accuracy: 0.5714\n",
      "Epoch 00415: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 4.3913 - accuracy: 0.5714 - val_loss: 11.6479 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9157 - accuracy: 0.5238\n",
      "Epoch 00416: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 5.9157 - accuracy: 0.5238 - val_loss: 9.8793 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.4481 - accuracy: 0.5238\n",
      "Epoch 00417: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 7.4481 - accuracy: 0.5238 - val_loss: 9.8965 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.6650 - accuracy: 0.5714\n",
      "Epoch 00418: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 6.6650 - accuracy: 0.5714 - val_loss: 8.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.9626 - accuracy: 0.5238\n",
      "Epoch 00419: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 5.9626 - accuracy: 0.5238 - val_loss: 6.6900 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.9847 - accuracy: 0.5714\n",
      "Epoch 00420: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 8.9847 - accuracy: 0.5714 - val_loss: 6.5964 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 4.3515 - accuracy: 0.6190\n",
      "Epoch 00421: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 4.3515 - accuracy: 0.6190 - val_loss: 6.5497 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1129 - accuracy: 0.6190\n",
      "Epoch 00422: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 5.1129 - accuracy: 0.6190 - val_loss: 6.4505 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.8347 - accuracy: 0.6190\n",
      "Epoch 00423: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 5.8347 - accuracy: 0.6190 - val_loss: 8.1556 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.6377 - accuracy: 0.4762\n",
      "Epoch 00424: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 6.6377 - accuracy: 0.4762 - val_loss: 8.1154 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.3957 - accuracy: 0.5714\n",
      "Epoch 00425: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 7.3957 - accuracy: 0.5714 - val_loss: 8.1438 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.3753 - accuracy: 0.5714\n",
      "Epoch 00426: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 7.3753 - accuracy: 0.5714 - val_loss: 8.1627 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.3252 - accuracy: 0.6190\n",
      "Epoch 00427: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 7.3252 - accuracy: 0.6190 - val_loss: 8.1598 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.2668 - accuracy: 0.6190\n",
      "Epoch 00428: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 7.2668 - accuracy: 0.6190 - val_loss: 8.1547 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.5654 - accuracy: 0.6190\n",
      "Epoch 00429: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 9.5654 - accuracy: 0.6190 - val_loss: 9.9448 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.5142 - accuracy: 0.6190\n",
      "Epoch 00430: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 9.5142 - accuracy: 0.6190 - val_loss: 9.9489 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.7974 - accuracy: 0.6190\n",
      "Epoch 00431: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 8.7974 - accuracy: 0.6190 - val_loss: 9.9458 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.1259 - accuracy: 0.6190\n",
      "Epoch 00432: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 7.1259 - accuracy: 0.6190 - val_loss: 9.9401 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.7113 - accuracy: 0.6190\n",
      "Epoch 00433: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 8.7113 - accuracy: 0.6190 - val_loss: 9.9306 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 9.4556 - accuracy: 0.4762\n",
      "Epoch 00434: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 9.4556 - accuracy: 0.4762 - val_loss: 8.1358 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 8.5457 - accuracy: 0.5714\n",
      "Epoch 00435: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 8.5457 - accuracy: 0.5714 - val_loss: 8.1499 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.0266 - accuracy: 0.5714\n",
      "Epoch 00436: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.0266 - accuracy: 0.5714 - val_loss: 9.9666 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.5714\n",
      "Epoch 00437: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 13.0480 - accuracy: 0.5714 - val_loss: 8.1877 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.4762\n",
      "Epoch 00438: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 12.2805 - accuracy: 0.4762 - val_loss: 8.2065 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.5714\n",
      "Epoch 00439: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 13.0480 - accuracy: 0.5714 - val_loss: 8.2643 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.5714\n",
      "Epoch 00440: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 13.0480 - accuracy: 0.5714 - val_loss: 8.2849 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.5238\n",
      "Epoch 00441: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 12.2805 - accuracy: 0.5238 - val_loss: 8.2941 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.5714\n",
      "Epoch 00442: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 13.0480 - accuracy: 0.5714 - val_loss: 6.4955 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8258 - accuracy: 0.4762\n",
      "Epoch 00443: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 13.8258 - accuracy: 0.4762 - val_loss: 6.4998 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0554 - accuracy: 0.4762\n",
      "Epoch 00444: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 13.0554 - accuracy: 0.4762 - val_loss: 4.6636 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7805 - accuracy: 0.5238\n",
      "Epoch 00445: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 10.7805 - accuracy: 0.5238 - val_loss: 4.8403 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.5238\n",
      "Epoch 00446: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 12.2805 - accuracy: 0.5238 - val_loss: 4.9707 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5479 - accuracy: 0.5714\n",
      "Epoch 00447: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 11.5479 - accuracy: 0.5714 - val_loss: 4.9458 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.5238\n",
      "Epoch 00448: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 13.0480 - accuracy: 0.5238 - val_loss: 4.9261 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.5830 - accuracy: 0.5238\n",
      "Epoch 00449: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 14.5830 - accuracy: 0.5238 - val_loss: 6.7212 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8198 - accuracy: 0.5714\n",
      "Epoch 00450: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 13.8198 - accuracy: 0.5714 - val_loss: 6.7356 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.5714\n",
      "Epoch 00451: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 13.0480 - accuracy: 0.5714 - val_loss: 6.7313 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8155 - accuracy: 0.5714\n",
      "Epoch 00452: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 13.8155 - accuracy: 0.5714 - val_loss: 6.7422 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.5714\n",
      "Epoch 00453: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 13.0480 - accuracy: 0.5714 - val_loss: 6.7405 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8155 - accuracy: 0.5714\n",
      "Epoch 00454: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 13.8155 - accuracy: 0.5714 - val_loss: 4.9650 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 14.1112 - accuracy: 0.5238\n",
      "Epoch 00455: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 14.1112 - accuracy: 0.5238 - val_loss: 4.9729 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1867 - accuracy: 0.5714\n",
      "Epoch 00456: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 13.1867 - accuracy: 0.5714 - val_loss: 5.0023 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.9517 - accuracy: 0.5238\n",
      "Epoch 00457: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 13.9517 - accuracy: 0.5238 - val_loss: 5.0273 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1793 - accuracy: 0.5238\n",
      "Epoch 00458: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 13.1793 - accuracy: 0.5238 - val_loss: 3.2395 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.4184 - accuracy: 0.5238\n",
      "Epoch 00459: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 12.4184 - accuracy: 0.5238 - val_loss: 11.3307 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.4080 - accuracy: 0.5238\n",
      "Epoch 00460: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 12.4080 - accuracy: 0.5238 - val_loss: 7.3010 - val_accuracy: 0.1111\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.9507 - accuracy: 0.4286\n",
      "Epoch 00461: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 13.9507 - accuracy: 0.4286 - val_loss: 7.3697 - val_accuracy: 0.1111\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.4090 - accuracy: 0.5238\n",
      "Epoch 00462: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 12.4090 - accuracy: 0.5238 - val_loss: 7.3770 - val_accuracy: 0.1111\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.9448 - accuracy: 0.5714\n",
      "Epoch 00463: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 13.9448 - accuracy: 0.5714 - val_loss: 7.4317 - val_accuracy: 0.1111\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1730 - accuracy: 0.5238\n",
      "Epoch 00464: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 13.1730 - accuracy: 0.5238 - val_loss: 7.4994 - val_accuracy: 0.1111\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.9423 - accuracy: 0.4762\n",
      "Epoch 00465: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 13.9423 - accuracy: 0.4762 - val_loss: 7.5445 - val_accuracy: 0.1111\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1750 - accuracy: 0.5238\n",
      "Epoch 00466: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 13.1750 - accuracy: 0.5238 - val_loss: 7.5851 - val_accuracy: 0.1111\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.9444 - accuracy: 0.5238\n",
      "Epoch 00467: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 13.9444 - accuracy: 0.5238 - val_loss: 7.6253 - val_accuracy: 0.1111\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1676 - accuracy: 0.4762\n",
      "Epoch 00468: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 13.1676 - accuracy: 0.4762 - val_loss: 6.0955 - val_accuracy: 0.1111\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1733 - accuracy: 0.3810\n",
      "Epoch 00469: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 13.1733 - accuracy: 0.3810 - val_loss: 4.6899 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 13.9408 - accuracy: 0.5238\n",
      "Epoch 00470: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 13.9408 - accuracy: 0.5238 - val_loss: 4.7363 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3973 - accuracy: 0.5238\n",
      "Epoch 00471: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 12.3973 - accuracy: 0.5238 - val_loss: 4.7854 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6391 - accuracy: 0.3810\n",
      "Epoch 00472: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 11.6391 - accuracy: 0.3810 - val_loss: 4.8257 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.2036 - accuracy: 0.4286\n",
      "Epoch 00473: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 13.2036 - accuracy: 0.4286 - val_loss: 1.6865 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1762 - accuracy: 0.4762\n",
      "Epoch 00474: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 13.1762 - accuracy: 0.4762 - val_loss: 1.7449 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.6269 - accuracy: 0.4762\n",
      "Epoch 00475: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 11.6269 - accuracy: 0.4762 - val_loss: 1.7798 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.4025 - accuracy: 0.4762\n",
      "Epoch 00476: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 12.4025 - accuracy: 0.4762 - val_loss: 1.8075 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.9345 - accuracy: 0.5238\n",
      "Epoch 00477: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 13.9345 - accuracy: 0.5238 - val_loss: 1.7387 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8548 - accuracy: 0.4286\n",
      "Epoch 00478: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 10.8548 - accuracy: 0.4286 - val_loss: 3.5387 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3934 - accuracy: 0.5238\n",
      "Epoch 00479: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 12.3934 - accuracy: 0.5238 - val_loss: 3.5594 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.9243 - accuracy: 0.4286\n",
      "Epoch 00480: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 13.9243 - accuracy: 0.4286 - val_loss: 3.5891 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3929 - accuracy: 0.5238\n",
      "Epoch 00481: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 12.3929 - accuracy: 0.5238 - val_loss: 3.6005 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1302 - accuracy: 0.5238\n",
      "Epoch 00482: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 13.1302 - accuracy: 0.5238 - val_loss: 3.6048 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1398 - accuracy: 0.5714\n",
      "Epoch 00483: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 13.1398 - accuracy: 0.5714 - val_loss: 3.6099 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8164 - accuracy: 0.5714\n",
      "Epoch 00484: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 10.8164 - accuracy: 0.5714 - val_loss: 3.5838 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1594 - accuracy: 0.4762\n",
      "Epoch 00485: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 13.1594 - accuracy: 0.4762 - val_loss: 3.4788 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3576 - accuracy: 0.5714\n",
      "Epoch 00486: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 12.3576 - accuracy: 0.5714 - val_loss: 5.1454 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.1193 - accuracy: 0.5714\n",
      "Epoch 00487: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 13.1193 - accuracy: 0.5714 - val_loss: 4.9712 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5983 - accuracy: 0.4762\n",
      "Epoch 00488: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 11.5983 - accuracy: 0.4762 - val_loss: 6.7537 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.7454 - accuracy: 0.4286\n",
      "Epoch 00489: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 10.7454 - accuracy: 0.4286 - val_loss: 6.7288 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0886 - accuracy: 0.4762\n",
      "Epoch 00490: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 13.0886 - accuracy: 0.4762 - val_loss: 6.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3254 - accuracy: 0.4286\n",
      "Epoch 00491: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 12.3254 - accuracy: 0.4286 - val_loss: 6.6308 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.3349 - accuracy: 0.5714\n",
      "Epoch 00492: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 12.3349 - accuracy: 0.5714 - val_loss: 8.4404 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.2805 - accuracy: 0.4286\n",
      "Epoch 00493: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 12.2805 - accuracy: 0.4286 - val_loss: 8.4530 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 12.4553 - accuracy: 0.4286\n",
      "Epoch 00494: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 12.4553 - accuracy: 0.4286 - val_loss: 8.4717 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.4762\n",
      "Epoch 00495: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 11.5129 - accuracy: 0.4762 - val_loss: 8.4991 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.8155 - accuracy: 0.4762\n",
      "Epoch 00496: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 13.8155 - accuracy: 0.4762 - val_loss: 8.5317 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 11.5129 - accuracy: 0.4762\n",
      "Epoch 00497: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 11.5129 - accuracy: 0.4762 - val_loss: 8.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.3810\n",
      "Epoch 00498: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 13.0480 - accuracy: 0.3810 - val_loss: 8.7460 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 13.0480 - accuracy: 0.5238\n",
      "Epoch 00499: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 13.0480 - accuracy: 0.5238 - val_loss: 10.0716 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 10.8931 - accuracy: 0.4762\n",
      "Epoch 00500: accuracy did not improve from 0.76190\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 10.8931 - accuracy: 0.4762 - val_loss: 10.0893 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#모델을 저장할 폴더\n",
    "MODEL_DIR = './model4/'\n",
    "\n",
    "#폴더가 없다면 생성\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "#loss값에 따라서 파일명을 지을거임\n",
    "modelpath = MODEL_DIR + '{epoch:02d}-{val_loss:.4f}-{accuracy:.4f}.hdf5'\n",
    "\n",
    "#모델이 오차범위를 수정하면서 정확도가 높아지면 파일을 갱신할거임\n",
    "mc = ModelCheckpoint(filepath = modelpath, #filepath : 저장할 파일경로\n",
    "               monitor = 'accuracy', verbose = 1, #monitor : 어떤걸 모니터(체크)할건가 ,   val_loss: 테스트오차, val_acc : 테스트 정확도, loss : 훈련오차 // verboss : 진행내용 출력여부 1출력 0미출력\n",
    "               save_best_only = 'True') #save_best_only : 가장높은 수치반영 True : 이전정확도보다 높으면 저장 // False : 낮으면 저장\n",
    "\n",
    "h= model.fit(x_ex, y_en, validation_split = 0.3, epochs=500, callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a7a6be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 400) (100, 400)\n"
     ]
    }
   ],
   "source": [
    "TEST_REAL_DIR = \"./wav/test_real/\"\n",
    "\n",
    "X_real = []\n",
    "\n",
    "for fname in os.listdir(TEST_REAL_DIR):\n",
    "    try:\n",
    "        # 읽은 파일이 wav 파일이 아닌 경우 다음으로 넘어감\n",
    "        if \".wav\" not in fname:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        ####테스트 주석#####\n",
    "        \n",
    "        # 라벨 데이터를 저장\n",
    "        # text는 파일 명?에서 따올 것\n",
    "        #text =fname[:len(fname)-4]\n",
    "        #ts = text.split(\"_\")\n",
    "        #print(ts)\n",
    "        #y_test.append(ts[0])\n",
    "        #y_test.append(ts[1])\n",
    "        \n",
    "        # wav 파일 데이터를 읽어온다\n",
    "        wav, sr = librosa.load(TEST_REAL_DIR+fname,sr=16000)\n",
    "        \n",
    "        pretreatment(wav)\n",
    "        \n",
    "        # mfcc 전환\n",
    "        mfcc_01 = librosa.feature.mfcc(wav_01)\n",
    "        mfcc_01 = librosa.feature.mfcc(wav_01, sr=16000, n_mfcc=100, n_fft=400, hop_length=160)\n",
    "        mfcc_02 = librosa.feature.mfcc(wav_02)\n",
    "        mfcc_02 = librosa.feature.mfcc(wav_02, sr=16000, n_mfcc=100, n_fft=400, hop_length=160)      \n",
    "        \n",
    "        zero_pad_01 = np.zeros((100,400-len(mfcc_01[0])))\n",
    "        mfcc_01 = np.hstack((mfcc_01,zero_pad_01)) \n",
    "        \n",
    "        zero_pad_02 = np.zeros((100,400-len(mfcc_02[0])))\n",
    "        mfcc_02 = np.hstack((mfcc_02,zero_pad_02)) \n",
    "        \n",
    "        print(mfcc_01.shape,mfcc_02.shape)\n",
    "        \n",
    "        # wav 파일을 동일한 길이로 잘라서 특성 데이터로 저장\n",
    "        # wav 데이터의 길이를 30000으로 설정\n",
    "        #mfcc_01 = np.expand_dims(mfcc_01, -1)\n",
    "        #mfcc_02 = np.expand_dims(mfcc_02, -1)\n",
    "        \n",
    "        X_real.append(mfcc_01)\n",
    "        X_real.append(mfcc_02)\n",
    "    except:\n",
    "        print(\"파일 읽기 오류\")\n",
    "        # 다음으로 넘어간다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95534bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real = np.array(X_real)\n",
    "\n",
    "X_real_ex = np.expand_dims(X_real, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8df87808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002E6A4258558> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "고생1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best=load_model('./model4/347-8.2445-0.7619.hdf5')\n",
    "\n",
    "pre = best.predict(X_real_ex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "15d278ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#기존에 학습데이터와 후에 들어올 새로운 데이터의 예측값을 비교하기위 해 predict를 사용하여 변수화\n",
    "pre_ex = best.predict(x_ex)\n",
    "\n",
    "#새로 들어온 데이터 예측값\n",
    "b_ex = best.predict(X_real_ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "941b3ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "18\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "23\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "26\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "27\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "28\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "b0 = b_ex[0]\n",
    "b1 = b_ex[1]\n",
    "\n",
    "for i in range(30):\n",
    "    for j in range(30):\n",
    "        if (pre_ex[i][j]/b0[j]).round() == 1:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d740842a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.66495955  0.5960745  -0.09068552 -0.13252155 -0.3187022  -0.05095164\n",
      "  -0.18578759 -0.2729661  -0.16558182 -0.21302947 -0.1468511   0.08035976\n",
      "  -0.36074615 -0.06869741 -0.1965251  -0.27323735 -0.18841591 -0.09469686\n",
      "  -0.20926294 -0.06343122 -0.09985084 -0.02726909 -0.027835    4.054705\n",
      "  -0.25826538 -0.12090027 -0.16812046 -0.04317562 -0.03216708 -0.06327869]\n",
      " [-0.19949062 -0.19873752 -0.09407944 -0.1412628  -0.31599128  0.01967904\n",
      "  -0.18743964 -0.27335283 -0.14031474 -0.20912707 -0.14560716 -0.08672564\n",
      "   2.9908848  -0.20787267 -0.05248486 -0.26445094 -0.13357942 -0.15678918\n",
      "  -0.17852671 -0.05104877 -0.12655227 -0.02851646  0.03477922 -0.07763653\n",
      "  -0.21434852 -0.07907297  0.3801695  -0.06756543 -0.0159988  -0.06067036]]\n"
     ]
    }
   ],
   "source": [
    "print(b_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e019edb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.882131e-14"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((b_ex[1] - pre_ex[5])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f50f9fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19949062, -0.19873752, -0.09407943, -0.1412628 , -0.31599125,\n",
       "        0.01967904, -0.18743964, -0.27335283, -0.14031471, -0.20912707,\n",
       "       -0.14560714, -0.08672564,  2.9908848 , -0.20787267, -0.052485  ,\n",
       "       -0.26445094, -0.13357939, -0.15678914, -0.17852671, -0.05104876,\n",
       "       -0.12655227, -0.02851646,  0.03477927, -0.07763653, -0.21434852,\n",
       "       -0.07907293,  0.38016975, -0.06756543, -0.01599878, -0.06067035],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_ex[5] #0~29   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f4dd6dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19949062, -0.19873752, -0.09407944, -0.1412628 , -0.31599128,\n",
       "        0.01967904, -0.18743964, -0.27335283, -0.14031474, -0.20912707,\n",
       "       -0.14560716, -0.08672564,  2.9908848 , -0.20787267, -0.05248486,\n",
       "       -0.26445094, -0.13357942, -0.15678918, -0.17852671, -0.05104877,\n",
       "       -0.12655227, -0.02851646,  0.03477922, -0.07763653, -0.21434852,\n",
       "       -0.07907297,  0.3801695 , -0.06756543, -0.0159988 , -0.06067036],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_ex[1] #0,1 // #[0] = 고생3 // [1] = 했어3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "26fd2458",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고생1\n"
     ]
    }
   ],
   "source": [
    "y_en_np = np.array(y_en)\n",
    "\n",
    "y_en\n",
    "    \n",
    "for i in range(len(pre)):\n",
    "    for j in range(len(pre)):\n",
    "        if not y_en.iloc[i][j] == 0:\n",
    "            y_name = y_en.iloc[:,j].name\n",
    "            print(y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e830166",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pre)):\n",
    "    for j in range(len(pre)):\n",
    "        if not y_en.iloc[i][j] == 0:\n",
    "            y_name = y_en.iloc[:,j].name\n",
    "            print(y_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4ce875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d2d965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d683da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfddbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91911723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097abe23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9132e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39291485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff61cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881cb666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1d12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eadd332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9a881b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aaba09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca55c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1731245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bc2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ccb82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd9251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58cacad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae4c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5634a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72f3943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ac765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a222d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa8599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906950d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8905a85d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d37bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150094db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216cf27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7fdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cfcb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba38dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c6611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08992fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2972abf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0159aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d05aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90937edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d89992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05957dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48301730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de370585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640b5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e705c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3a2f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d08f5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff3668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c194f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f709829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
